---
title: "Inflación"
output: html_document
date: "2024-03-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1) Definición

## Descripción del Problema

Una serie de tiempo del Índice de Precios al Consumidor (IPC), con datos desde enero de 2008 hasta enero de 2024, muestra el cambio porcentual en los precios de una canasta de bienes y servicios consumidos por los hogares. Esta secuencia cronológica de mediciones mensuales refleja cómo han cambiado los costos de vida y el poder adquisitivo de los consumidores en una economía a lo largo del tiempo. Al analizar estas variaciones mensuales, se pueden identificar tendencias, ciclos y patrones estacionales en el comportamiento del consumo y los precios, proporcionando una comprensión detallada de las respuestas a corto plazo del mercado a los cambios económicos, políticos y sociales. La periodicidad mensual del IPC permite una evaluación precisa de su volatilidad, crucial para la toma de decisiones económicas y políticas.

### La elección de esta serie de tiempo es esencial por varias razones:

Comprensión del Costo de Vida: El IPC es un indicador fundamental para medir el costo de vida y el poder adquisitivo. Analizar su evolución ayuda a evaluar el bienestar económico de los consumidores.
Política Monetaria y Fiscal: Para los responsables de la formulación de políticas, entender las tendencias del IPC es vital para ajustar la política monetaria y fiscal, influenciando la inflación y el crecimiento económico.
Indexación de Contratos: El IPC se usa frecuentemente para la indexación de contratos, incluyendo salarios, pensiones, y alquileres, ajustándolos por la inflación para mantener el poder adquisitivo.
Impacto en la Economía: Las variaciones en el IPC afectan directamente a casi todos los aspectos de la economía, desde las decisiones de los consumidores hasta las políticas gubernamentales y la planificación empresarial.

##Qué Quiero Visualizar

Tendencias a Largo Plazo: Cómo ha evolucionado el IPC a lo largo de las décadas, identificando patrones cíclicos o tendencias persistentes.
Volatilidad: Identificar periodos de alta volatilidad en el IPC y los eventos que pudieron haber contribuido a estos cambios.
Comparaciones: Comparar el IPC con otros indicadores económicos, como el PIB y la tasa de desempleo, para comprender mejor las interacciones dentro de la economía y su impacto en el costo de vida.

##Resultados Esperados y su Utilidad

Identificación de Patrones y Tendencias: Obtener una comprensión clara de la dinámica del IPC a lo largo del tiempo, incluyendo cualquier patrón estacional o tendencia a largo plazo que pueda influir en las decisiones económicas.
Comprensión de la Volatilidad: Identificar los periodos de mayor volatilidad en el IPC y explorar sus posibles causas, lo que puede ser crucial para anticipar cambios en el costo de vida.
Pronósticos Mejorados: Utilizar el análisis de series de tiempo para mejorar la precisión de los pronósticos sobre el comportamiento futuro del IPC, facilitando una mejor planificación y toma de decisiones económicas.
Estos resultados no solo informarán mejor a los formuladores de políticas, inversores y analistas económicos, sino que también proporcionarán a la sociedad una mejor comprensión de las tendencias de precios y el costo de vida, facilitando la planificación financiera personal y empresarial. Este análisis profundo del IPC permitirá adaptar estrategias económicas y políticas más efectivas para mantener la estabilidad y promover el bienestar económico.

# 2) Datos

Banxico junto con INEGI tiene la facultad exclusiva de elaborar y publicar los índices nacionales de precios.

Los datos de Banxico pueden ser descargados en el siguiente [enlace](https://www.banxico.org.mx/SieInternet/consultarDirectorioInternetAction.do?accion=consultarCuadro&idCuadro=CP151&sector=8&locale=es#contenidoPrincipal)

```{r message=FALSE, warning=FALSE}
library(tsibble)
library(fable)
library(readxl)
library(ggplot2)
library(dplyr)
library(forecast)
library(ggplot2)
library(broom)
library(fabletools)
library(EnvStats)
library(plotly)
library(tidyr)
library(lubridate)
library(feasts)
library(ggExtra)
library(tidyverse)
```

## Importar

```{r}
data <- read_xlsx("/Users/ayelenhurtado/OneDrive - ITESO/Series de tiempo/INPC.xlsx")
data
```

## Renombrar columnas 

```{r}
colnames(data) = c('date', 'value')
data
```

## Periodicidad Mensual 

```{r}
data$date <- as.Date(data$date)
data$date = seq(from = min(data$date), to = max(data$date), by = "1 month")
data$date = yearmonth(data$date)
data
```

## Importación como Tsibble

```{r}
data = as_tsibble(data, index=date, regular=TRUE)
data
```

# 3) Análisis

## Visualización de la serie

```{r}
feasts::autoplot(data) + ggtitle('INPC por mes') + ylab('INPC Mensual') + xlab('Fecha')
```
### Gráficas estacionales

```{r}
data %>% gg_season(value, labels = "both") +
    ggtitle('INPC') + ylab('Tendencia anual') + xlab('Mes')
```

#### Gráfica Interactiva

```{r}
yearly_data_plot = data %>% gg_season(value, labels = "both") +
    ggtitle('INPC') + ylab('Tendencia anual') + xlab('Mes')

ggplotly(yearly_data_plot)
```

### Sub gráficas estacionales

```{r}
subseries_plot = data %>% gg_subseries(value)
ggplotly(subseries_plot)
```

### Gráfico de rezagos

```{r}
lags_plots = data %>% filter(year(date) > 2018) %>% gg_lag(value, geom = "point", lags = 1:12) + labs(x = "lag(INPC, k)")

suppressWarnings(ggplotly(lags_plots))
```

### Autocorrelación

Así como la correlación mide el alcance de una relación lineal entre dos variables, la autocorrelación mide la relación lineal entre valores rezagados de una serie temporal.

```{r}
data %>% ACF(value, lag_max = 12)
```

```{r}
data %>% ACF(value, lag_max = 36) %>% autoplot() + labs(title='Autocorrelacion INPC')
```

## Estadística descriptiva

### Medidas de tendencia central

```{r}
print(paste('fecha inicial', min(data$date)))
print(paste('fecha final', max(data$date)))
print(paste('observaciones', nrow(data)))
print(paste('existen', sum(is.na(data)), 'datos faltantes'))
```
```{r}
summary(data[, 'value'])
```
Observamos que, por mes, en inpc promedio es de 40.1296.
El INPC minimo es de 0.0122 y el máxima fue de 133.5550.

```{r}
boxplot = data %>% 
            mutate(year = year(date)) %>% 
            ggplot(aes(x = as.factor(year), y = value)) + 
            geom_boxplot() + 
            xlab('Año') + 
            ylab('Inflación mensual(%)')

ggplotly(boxplot)
```


### Medidas de dispersión

```{r}
sd(data$value)
var(data$value)
kurtosis(data$value)
skewness(data$value)
shapiro.test(data$value)
```

```{r}
p <- ggplot(data, aes(x=date, y=value)) + 
        geom_hline(yintercept =10) + 
        geom_hline(yintercept =70) +
        geom_point() + 
        ggtitle('Remesas por mes') + ylab('Inflación Mensual') + xlab('Fecha')

ggMarginal(p, type='histogram', margins = 'y')
```

```{r}
histogram = ggplot(data, aes(x = value)) +
  geom_histogram( bins = 20, fill = "black", color = "black", alpha = 0.5) +
  labs(title = "Histograma",
       x = "Value",
       y = "Densidad")

ggplotly(histogram)
```

### Valores atípicos

La detección de outliers es importante para afinar nuestro pronóstico y eliminar las observaciones atípicas.

Este código está diseñado para detectar valores atípicos (outliers) en un conjunto de datos, basándose en la definición de valores atípicos como aquellos que se encuentran a más de 1.5 y 3 veces el rango intercuartílico (IQR) por encima o por debajo del primer y tercer cuartil, respectivamente.

```{r}
ttl_m_dlrs <- data %>% select('value')
ttl_m_dlrs <- as.numeric(unlist(ttl_m_dlrs[,1]))

summary(ttl_m_dlrs)[2] - 1.5*IQR(ttl_m_dlrs) >= summary(ttl_m_dlrs)[1]
summary(ttl_m_dlrs)[5] + 1.5*IQR(ttl_m_dlrs) <= summary(ttl_m_dlrs)[6]

summary(ttl_m_dlrs)[2] - 3*IQR(ttl_m_dlrs) >= summary(ttl_m_dlrs)[1]
summary(ttl_m_dlrs)[5] + 3*IQR(ttl_m_dlrs) <= summary(ttl_m_dlrs)[6]
```
No indican valores atípicos.

CÓDIGO PARA QUITAR LOS VALORES ATÍPICOS. 
# Calcula el primer y tercer cuartil, y el IQR para la columna 'value'
Q1 <- quantile(data$value, 0.25, na.rm = TRUE)
Q3 <- quantile(data$value, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1

# Define los límites para considerar un valor como atípico
lower_bound_strict <- Q1 - 3 * IQR
upper_bound_strict <- Q3 + 3 * IQR

# En lugar de filtrar y eliminar, reemplaza valores atípicos con NA
data <- data %>%
  mutate(value = ifelse(value < lower_bound_strict | value > upper_bound_strict, NA, value))

# Ahora realiza la imputación de valores NA con el último valor conocido
data <- data %>%
  fill(value, .direction = "down")
data


```{r}
p <- data %>% as_tibble %>% group_by(years=year(date)) %>%
    summarise(inpc=sum(value)) %>%
    arrange(desc(years))%>%
    mutate(change = (inpc/lead(inpc) - 1) * 100) %>% 
    filter(years > 1995) %>% 
    filter(years < 2023)

mean_growth <- data %>% as_tibble %>% group_by(years=year(date)) %>%
                    summarise(inpc=sum(value)) %>%
                    arrange(desc(years))%>%
                    mutate(change = (inpc/lead(inpc) - 1) * 100) %>% 
                    filter(years > 1970) %>% 
                    filter(years < 2023) %>%
                    summarise(mean(change))

mean_growth <- mean_growth$`mean(change)`

ggplot(p, aes(x=years, y=change)) +
    geom_line() +
    geom_hline(yintercept=mean_growth) +
    geom_hline(yintercept=0) +
    ggtitle('Cambio porcentual por año') + ylab('%') + xlab('Año')
```

El crecimiento promedio es de 11.48%.

# 4) Pronósticos base

## Define los periodos de prueba y entrenamiento

```{r}
train <- data %>% select(value) %>% filter_index("2008 Jan" ~ "2023 Jun")
test <- data %>% select(value) %>% filter_index("2023 Jul" ~ "2024 Jan")
train
test
h = 12
```
## Seasonal Naive


```{r}
# Ajustar modelo y hacer pronóstico
models_fit <- train %>% 
    model(`Seasonal naive` = SNAIVE(value))
models_tst <- models_fit %>% forecast(h = h)  

# Visualización con autoplot
snaive_plot <- models_tst %>% autoplot(filter_index(data, "2010 Jan" ~ .)) +  
    ggtitle('Seasonal Naive') + ylab('Inflacion') + xlab('Mes')

snaive_plot
```

### Intervalos de predicción. 

```{r}
models_tst
models_tst %>% hilo(level = c(80, 95))
```

### Errores de pronóstico

```{r}
accuracy(models_fit)
```
```{r}
(models_fit %>% forecast(h = 12) %>% accuracy(test))
```
### Diagnostico de resiuales

```{r}
aug = augment(models_fit)
aug
```
```{r}
aug %>% pull(.resid) %>% mean(na.rm = TRUE)
```

```{r}
aug %>% autoplot(.resid) + xlab("Mes") + ylab("") +
  ggtitle("Residuales del método seasonal naïve")
```

```{r}
aug %>%
  ggplot(aes(x = .resid)) +
  geom_histogram() +
  ggtitle("Histograma de los residuales")
```
```{r}
aug %>% ACF(.resid)
```

```{r}
aug %>% ACF(.resid) %>% autoplot() + ggtitle("ACF of residuals")
```

```{r}
train %>% 
  model(SNAIVE(value)) %>% 
  gg_tsresiduals()
```

### Test de Ljung-Box
Un test relacionado y que, generalmente, es más preciso es el test de Ljung-Box.

En este caso es igual: valores grandes de la prueba son indicios de que las autocorrelaciones no provienen de ruido blanco.

>Entonces, la hipótesis nula de estas pruebas es que la serie en cuestión no está autocorrelacionada. En otras palabras, la H0 dice que la serie es ruido blanco. Si α es el nivel de significancia (el nivel máximo de error que estamos dispuestos a aceptar) y si el ¨p-value <α, entonces rechazamos H0, de lo contrario, no rechazamos la H0.

```{r}
aug %>% features(.resid, ljung_box, lag=12, dof=0)
```

# 5) Descomposición

## Componentes y descomposición STL

```{r}
stl_model = data %>% dplyr::select(value) %>% stl(s.window = 'per')
plot(stl_model,main = 'Descomposicón de la serie con STL')
```

## Transformaciones y adjustes

```{r}
qqnorm(data$value)
qqline(data$value)
```

# 6) Pronósticos base con STL y tranformación matemática

## STL Seasonal Naive

```{r}
models_fit <- train %>% 
  model(stlf = decomposition_model(
    STL(log(value) ~ trend(window = 12), robust = TRUE),
    NAIVE(season_adjust)
  ))
models_tst <- models_fit %>% forecast(h = h)
mape_sn <- (models_fit %>% forecast(h = h) %>% accuracy(test))$MAPE
snaive_plot <- models_tst %>% autoplot(filter_index(data, "2018 Jan"~ "2024 Jan")) +
    ggtitle('STL') + ylab('Variacion % mensual de la inflación') + xlab('Mes')

snaive_plot
```

```{r}
models_fit <- train %>% 
  model(
    `Seasonal naive` = SNAIVE(value),
    stlf = decomposition_model(
    STL(value ~ trend(window = 12), robust = TRUE),
    NAIVE(season_adjust)),
    log_stlf = decomposition_model(
            STL(log(value) ~ trend(window = 12), robust = TRUE),
            NAIVE(season_adjust))
  )
models_tst <- models_fit %>% forecast(h = h)
mape_sn <- (models_fit %>% forecast(h = h) %>% accuracy(test))$MAPE
snaive_plot <- models_tst %>% autoplot(filter_index(data, "2018 Jan" ~ .), level = NULL) +
    ggtitle('Diferentes modelos') + ylab('Inflacion') + xlab('Mes')

snaive_plot
```

```{r}
accuracy(models_fit)
```
```{r}
models_fit[1] %>% gg_tsresiduals()
```

# 7) Regresión Lineal

## Datos

El INPC puede ser relevante para la estimación de la inflación.

```{r}
ipp <- read_xlsx("/Users/ayelenhurtado/OneDrive - ITESO/Series de tiempo/IPP.xlsx")
ipp
```
```{r}
colnames(ipp) = c('fecha', 'ipp')
ipp
```

```{r}
ipp$fecha <- as.Date(ipp$fecha)
ipp$fecha = yearmonth(ipp$fecha)
ipp
```
```{r}
ipp = as_tsibble(ipp, index=fecha, regular=TRUE)
ipp
```

### Separa entre entrenamiento y prueba

```{r}
train_ipp <- ipp %>% select(ipp) %>% filter_index("2008 Jan" ~ "2023 Jun")
test_ipp <- ipp %>% select(ipp) %>% filter_index("2023 Jul" ~ "2024 Jan")
train_ipp
test_ipp
```
### Renombrar las columnas

```{r}
train_ipp = add_column(train_ipp, train$value) #append remesas
colnames(train_ipp)[3] = "inpc" 
colnames(train_ipp)[1] = "ipp"

test_ipp = add_column(test_ipp, test$value)
colnames(test_ipp)[3] = "inpc"
colnames(test_ipp)[1] = "ipp"

train_ipp
test_ipp
```
### Gráfica de ambas series a traves del tiempo

```{r}
train_ipp |>
  pivot_longer(c(inpc, ipp), names_to="Series") |>
  autoplot(value) +
  labs(y = "value")
```

### Gráfica de disperción (correlación) entre ambas series

```{r}
train_ipp %>% ggplot(aes(x = ipp, y = log(inpc))) +
  labs(y = "INPC",
       x = "IPP") +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```
## Ajuste de regresión y reporte del modelo

```{r}
fit_lm <- train_ipp |>
  model(tslm = TSLM(log(inpc) ~ ipp))

report(fit_lm)
```
### Tabla aumentada del ajuste del modelo

```{r}
augment(fit_lm)
```

### Valores calculados

```{r}
plot_lm = augment(fit_lm) |>
  ggplot(aes(x = fecha)) +
  geom_line(aes(y = inpc, colour = "reales")) +
  geom_line(aes(y = .fitted, colour = "ajustados")) +
  labs(y = NULL,
    title = "inpc"
  ) +
  guides(colour = guide_legend(title = NULL))
ggplotly(plot_lm)
```

### Analisis de residuales

Primera gráfica: errores en el tiempo para evaluar media y varianza.
Segunda gráfica: autocorrelación de errores: errores en el pasado afectan el valor actual.
tercera gráfica: histograma de errores para verificar la normalidad, media sea 0 y sesgo sea 0.

```{r}
fit_lm %>% gg_tsresiduals()
```

```{r}
augment(fit_lm) %>% features(.innov, ljung_box, lag=12)
```

### Gráfica de residuales contra valores ajustados.

También sirve para identificar outliers

```{r}
augment(fit_lm) %>% ggplot(aes(x=.fitted, y=.resid)) + geom_point() + labs(x="Fitted", y="Residuals")
```

### Pronósticos

```{r}
test_ipp[c("ipp", "fecha")]
```

### Gráfica de prónosticos

```{r}
fc_lm = forecast(fit_lm, new_data = test_ipp[c("ipp", "fecha")])
data %>% autoplot(value) + autolayer(fc_lm)
```

### Table de prónosticos

```{r}
fc_lm
```

### Crea una variable dummy de valores atípicos para tu serie de tiempo


train_inf = train_inf %>%
    mutate(crisisp = if_else(fecha >= as.Date("1982-11-01") & 
                               fecha <= as.Date("1983-11-01"), 1, 0),
           
           crisisp1 = if_else(fecha >= as.Date("1986-06-01") & 
                               fecha <= as.Date("1988-10-01"), 1, 0))

test_inf = test_inf %>%
    mutate(crisisp = if_else(fecha >= as.Date("1982-11-01") & 
                               fecha <= as.Date("1983-11-01"), 1, 0),
           
           crisisp1 = if_else(fecha >= as.Date("1986-06-01") & 
                               fecha <= as.Date("1988-10-01"), 1, 0))

### Rezagos

Usa los valores pasados cómo predictor de X. 
Hipotesis: El inpc pasado influye en el futuro. Revisa la autocorrelación.

El siguiente código muestra como calcular una variable con rezagos = 1

```{r}
train_ipp$lag1 = c(NA, train_ipp$inpc[1:length(train_ipp$inpc)-1])
train_ipp

test_ipp$lag1 = c(train_inf$inpc[length(train_ipp$inpc)], test_ipp$inpc[1:length(test_ipp$inpc)-1])
test_ipp
```

### fourier

```{r}
fit_lm <- train_ipp |>
  model(tslm = TSLM(log(inpc) ~ ipp + ipp ))

report(fit_lm)
```
## regresión lineal múltiple

```{r}
fit_lm <- train_ipp |>
  model(tslm = TSLM(log(inpc) ~ trend() + season() + ipp + fourier(K = 2)))

report(fit_lm)
```

### Selección de variables

```{r}
glance(fit_lm) |>
  select(adj_r_squared, CV, AIC, AICc, BIC)
```
### Análisis de residuales

```{r}
fit_lm %>% gg_tsresiduals()
```

# 8) Suavización exponencial

### Simple

```{r}
fit_es <- train |>
  model(ETS(value ~ error("A") + trend("N") + season("N")))

report(fit_es)
```

```{r}
plot_lm = augment(fit_es) |>
  ggplot(aes(x = date)) +
  geom_line(aes(y = value, colour = "reales")) +
  geom_line(aes(y = .fitted, colour = "ajustados")) +
  labs(y = NULL,
    title = "INPC"
  ) +
  guides(colour = guide_legend(title = NULL))
ggplotly(plot_lm)
```


### Con tendencia

```{r}
fit_es <- train |>
  model(AAN = ETS(value ~ error("A") + trend("A") + season("N")))

report(fit_es)
```
```{r}
plot_lm = augment(fit_es) |>
  ggplot(aes(x = date)) +
  geom_line(aes(y = value, colour = "reales")) +
  geom_line(aes(y = .fitted, colour = "ajustados")) +
  labs(y = NULL,
    title = "INPC"
  ) +
  guides(colour = guide_legend(title = NULL))
ggplotly(plot_lm)
```

```{r}
fit_es <- train |>
  model(Damped = ETS(value ~ error("A") + trend("Ad") + season("N")))

report(fit_es)
```

```{r}
plot_lm = augment(fit_es) |>
  ggplot(aes(x = date)) +
  geom_line(aes(y = value, colour = "reales")) +
  geom_line(aes(y = .fitted, colour = "ajustados")) +
  labs(y = NULL,
    title = "INPC"
  ) +
  guides(colour = guide_legend(title = NULL))
ggplotly(plot_lm)
```

### Con estacionalidad


```{r}
fit_es <- train |>
  model(AAA = ETS(value ~ error("A") + trend("A") + season("A")))

report(fit_es)
```
```{r}
plot_lm = augment(fit_es) |>
  ggplot(aes(x = date)) +
  geom_line(aes(y = value, colour = "reales")) +
  geom_line(aes(y = .fitted, colour = "ajustados")) +
  labs(y = NULL,
    title = "INPC"
  ) +
  guides(colour = guide_legend(title = NULL))
ggplotly(plot_lm)
```

```{r}
train
```



```{r}
fit_es <- train |>
  model(AAA = ETS(value ~ error("M") + trend("A") + season("M")))

report(fit_es)
```

```{r}
plot_lm = augment(fit_es) |>
  ggplot(aes(x = date)) +
  geom_line(aes(y = value, colour = "reales")) +
  geom_line(aes(y = .fitted, colour = "ajustados")) +
  labs(y = NULL,
    title = "INPC"
  ) +
  guides(colour = guide_legend(title = NULL))
ggplotly(plot_lm)
```

### Selección del modelo

```{r}
fit_es <- train |>
  model(ETS(value))

report(fit_es)
```


```{r}
components(fit_es) |>
  autoplot()
```

### Pronostico, intervalo de predicción y análisis de residuales


```{r}
frcst = fit_es %>% forecast(h = 20)

fit_es %>%
  forecast(h = 20) %>%
  autoplot(train)
```
```{r}
frcst
```

```{r}
frcst %>% hilo(level = c(80, 95))
```


```{r}
accuracy(fit_es)
```


```{r}
accuracy(fit_lm)
```

```{r}
fit_es %>% gg_tsresiduals()
```

# 9) Arima 

## Estacionariedad y diferenciación

```{r}
train %>% ACF(value) %>% autoplot()
```

```{r}
train %>% ACF(difference(value)) %>% autoplot()
```

```{r}
train %>% features(value, unitroot_kpss)
```

La serie no estacionaria de acuerdo a las gráficas y la prueba unitaria.?

```{r}
train %>% features(difference(value), unitroot_kpss)
```
Con una diferenciación, aceptamos la prueba de hipótesis que la serie es estacionaría.?

```{r}
train %>% mutate(diff = difference(value)) %>% autoplot(diff)
```

La gráfica tiene reversión a la media, aunque su varianza no es constante.

```{r}
train %>% mutate(diff = difference(log(value))) %>% autoplot(diff)
```

```{r}
train %>% gg_tsdisplay(plot_type = "partial")
```

## Selección del modelo

```{r}
fit_arima = train %>% model(ARIMA(log(value)))
report(fit_arima)
```

sin especificar ningún parámetro 

```{r}
accuracy(fit_arima)
```

```{r}
accuracy(fit_es)
```

```{r}
accuracy(fit_lm)
```

Arima es el que tiene menor error. 

Podemos borrar esto?
```{r}
frcst = fit_arima %>% forecast(h = h)

fit_es %>%
  forecast(h = h) %>%
  autoplot(train)
```

# 10) Regresión dinámica

```{r}
train_ipp = train_ipp %>% mutate(diff = difference(log(inpc)))

fit_din = train_ipp %>% model(TSLM(diff ~ trend() + season()))

report(fit_din)

fit_din %>% gg_tsresiduals()
```


```{r}
fit_din = train_ipp %>% model(ARIMA(diff ~ trend() + season()))

report(fit_din)

fit_din %>% gg_tsresiduals()
```

```{r}
fit_din = train_ipp %>% model(ARIMA(log(inpc) ~ trend() + season()))

report(fit_din)
fit_din %>% gg_tsresiduals()
```

# 11) Compara los diferentes modelos y pronóstica

## Selección

Primero comparamos errores utilizando los datos de prueba.

```{r}
fit_sn %>% forecast(h = h) %>% accuracy(test)
#models_tst <- fit_sn %>% forecast(h = tstng_prds)
#fit_sn %>% accuracy(test)
```

```{r}
fc_lm = forecast(fit_lm, new_data = test_ipp[c("ipp", "fecha", "lag1")])
fc_lm %>% accuracy(test_ipp)
```

```{r}
fit_es %>% forecast(h=h) %>% accuracy(test)
```

```{r}
fit_arima %>% forecast(h=h) %>% accuracy(test)
```

```{r}
fc_din = forecast(fit_din, new_data = test_ipp[c("fecha", "lag1")])
fc_din %>% accuracy(test_ipp)
```

```{r}
fit_arima = data %>% model(ARIMA(log(value)))
report(fit_arima)
```

## Pronóstico

```{r}
forecast_arima = forecast(fit_arima, h = 12)
forecast_arima
forecast_arima %>% autoplot(data) 
```

```{r}
augmentt = augment(fit_arima)
plot = ggplot()+
  geom_line(aes(x = augmentt$date, y = augmentt$value, colour = "reales")) +
  geom_line(aes(x = augmentt$date, y = augmentt$.fitted, colour = "ajustados")) +
  geom_line(aes(x = forecast_arima$date, y = forecast_arima$.mean, colour = "pronóstico"))+
  labs(y = NULL,
    title = "IPC"
  ) +
  guides(colour = guide_legend(title = NULL))
ggplotly(plot)
```

```{r}
frcst %>% hilo(level = c(80, 95))
```
